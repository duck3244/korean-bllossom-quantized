#!/bin/bash

# Korean Bllossom AICA-5B ì–‘ìí™” í”„ë¡œì íŠ¸ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
# Ubuntu 22.04 ê¸°ì¤€

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

echo "ğŸŒ¸ Korean Bllossom AICA-5B ì–‘ìí™” í”„ë¡œì íŠ¸ ì„¤ì¹˜"
echo "================================================"
echo "ì‹œìŠ¤í…œ: Ubuntu 22.04"
echo "íƒ€ê²Ÿ GPU: RTX 4060 8GB"
echo "================================================"

# ìƒ‰ê¹” ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ë¡œê¹… í•¨ìˆ˜
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
check_system() {
    log_info "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘..."
    
    # Ubuntu ë²„ì „ í™•ì¸
    if ! grep -q "22.04" /etc/os-release; then
        log_warning "Ubuntu 22.04ê°€ ì•„ë‹™ë‹ˆë‹¤. í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    fi
    
    # Python ë²„ì „ í™•ì¸
    PYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2)
    if [ "$(echo "$PYTHON_VERSION < 3.8" | bc)" -eq 1 ]; then
        log_error "Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬: $PYTHON_VERSION"
        exit 1
    fi
    log_success "Python ë²„ì „ í™•ì¸: $PYTHON_VERSION"
    
    # ë©”ëª¨ë¦¬ í™•ì¸
    TOTAL_RAM=$(free -g | awk '/^Mem:/{print $2}')
    if [ "$TOTAL_RAM" -lt 16 ]; then
        log_warning "RAMì´ ${TOTAL_RAM}GBì…ë‹ˆë‹¤. 16GB ì´ìƒ ê¶Œì¥í•©ë‹ˆë‹¤."
    else
        log_success "RAM í™•ì¸: ${TOTAL_RAM}GB"
    fi
    
    # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
    FREE_SPACE=$(df . | tail -1 | awk '{print $4}')
    FREE_SPACE_GB=$((FREE_SPACE / 1024 / 1024))
    if [ "$FREE_SPACE_GB" -lt 50 ]; then
        log_warning "ì—¬ìœ  ë””ìŠ¤í¬ ê³µê°„ì´ ${FREE_SPACE_GB}GBì…ë‹ˆë‹¤. 50GB ì´ìƒ ê¶Œì¥í•©ë‹ˆë‹¤."
    else
        log_success "ë””ìŠ¤í¬ ê³µê°„ í™•ì¸: ${FREE_SPACE_GB}GB"
    fi
}

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
update_system() {
    log_info "ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ì¤‘..."
    sudo apt update -qq
    sudo apt upgrade -y -qq
    log_success "ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì™„ë£Œ"
}

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
install_system_packages() {
    log_info "ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    
    PACKAGES=(
        python3-pip
        python3-venv
        python3-dev
        build-essential
        curl
        wget
        git
        htop
        nvtop
        tree
        unzip
        software-properties-common
        apt-transport-https
        ca-certificates
        gnupg
        lsb-release
    )
    
    for package in "${PACKAGES[@]}"; do
        if ! dpkg -l | grep -q "^ii  $package "; then
            log_info "ì„¤ì¹˜ ì¤‘: $package"
            sudo apt install -y "$package" -qq
        else
            log_info "ì´ë¯¸ ì„¤ì¹˜ë¨: $package"
        fi
    done
    
    log_success "ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
}

# NVIDIA ë“œë¼ì´ë²„ í™•ì¸ ë° ì„¤ì¹˜
setup_nvidia() {
    log_info "NVIDIA ì„¤ì • í™•ì¸ ì¤‘..."
    
    if ! command -v nvidia-smi &> /dev/null; then
        log_error "NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!"
        echo "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:"
        echo "1. ìë™ ì„¤ì¹˜ (ê¶Œì¥)"
        echo "2. ìˆ˜ë™ ì„¤ì¹˜ í›„ ì¬ì‹œì‘"
        echo "3. ê±´ë„ˆë›°ê¸° (CPU ëª¨ë“œ)"
        
        read -p "ì„ íƒ (1-3): " choice
        case $choice in
            1)
                log_info "NVIDIA ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜ ì¤‘..."
                sudo ubuntu-drivers autoinstall
                log_warning "ì„¤ì¹˜ ì™„ë£Œ í›„ ì‹œìŠ¤í…œì„ ì¬ë¶€íŒ…í•´ì•¼ í•©ë‹ˆë‹¤."
                echo "ì¬ë¶€íŒ… í›„ ë‹¤ì‹œ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: ./setup.sh --resume"
                exit 0
                ;;
            2)
                log_info "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ìˆ˜ë™ ì„¤ì¹˜í•˜ì„¸ìš”:"
                echo "sudo ubuntu-drivers devices"
                echo "sudo ubuntu-drivers autoinstall"
                echo "sudo reboot"
                exit 0
                ;;
            3)
                log_warning "CPU ëª¨ë“œë¡œ ê³„ì†í•©ë‹ˆë‹¤. ì„±ëŠ¥ì´ ë§¤ìš° ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                ;;
        esac
    else
        log_success "NVIDIA ë“œë¼ì´ë²„ í™•ì¸ë¨"
        nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits
        
        # VRAM í™•ì¸
        VRAM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
        VRAM_GB=$((VRAM / 1024))
        
        if [ "$VRAM_GB" -lt 6 ]; then
            log_warning "VRAMì´ ${VRAM_GB}GBì…ë‹ˆë‹¤. 6GB ì´ìƒ ê¶Œì¥í•©ë‹ˆë‹¤."
        else
            log_success "VRAM í™•ì¸: ${VRAM_GB}GB"
        fi
    fi
}

# Python ê°€ìƒí™˜ê²½ ì„¤ì •
setup_python_env() {
    log_info "Python ê°€ìƒí™˜ê²½ ì„¤ì • ì¤‘..."
    
    ENV_NAME="bllossom_env"
    
    # ê¸°ì¡´ í™˜ê²½ ì œê±° (ì„ íƒì‚¬í•­)
    if [ -d "$ENV_NAME" ]; then
        read -p "ê¸°ì¡´ ê°€ìƒí™˜ê²½ì„ ì¬ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " recreate
        if [[ $recreate =~ ^[Yy]$ ]]; then
            rm -rf "$ENV_NAME"
            log_info "ê¸°ì¡´ ê°€ìƒí™˜ê²½ ì œê±°ë¨"
        fi
    fi
    
    # ê°€ìƒí™˜ê²½ ìƒì„±
    if [ ! -d "$ENV_NAME" ]; then
        log_info "ê°€ìƒí™˜ê²½ ìƒì„± ì¤‘..."
        python3 -m venv "$ENV_NAME"
        log_success "ê°€ìƒí™˜ê²½ ìƒì„± ì™„ë£Œ: $ENV_NAME"
    fi
    
    # ê°€ìƒí™˜ê²½ í™œì„±í™”
    source "$ENV_NAME/bin/activate"
    log_success "ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨"
    
    # pip ì—…ê·¸ë ˆì´ë“œ
    log_info "pip ì—…ê·¸ë ˆì´ë“œ ì¤‘..."
    pip install --upgrade pip setuptools wheel
    log_success "pip ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ"
}

# PyTorch ì„¤ì¹˜
install_pytorch() {
    log_info "PyTorch ì„¤ì¹˜ ì¤‘..."
    
    # CUDA ë²„ì „ í™•ì¸
    if command -v nvidia-smi &> /dev/null; then
        CUDA_VERSION=$(nvidia-smi | grep "CUDA Version" | awk '{print $9}' | cut -d'.' -f1,2)
        log_info "ê°ì§€ëœ CUDA ë²„ì „: $CUDA_VERSION"
        
        # CUDA ë²„ì „ì— ë”°ë¥¸ PyTorch ì„¤ì¹˜
        case $CUDA_VERSION in
            "12.1"|"12.2"|"12.3"|"12.4")
                log_info "CUDA 12.xìš© PyTorch ì„¤ì¹˜..."
                pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
                ;;
            "11.8"|"11.7")
                log_info "CUDA 11.xìš© PyTorch ì„¤ì¹˜..."
                pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
                ;;
            *)
                log_warning "ì§€ì›ë˜ì§€ ì•ŠëŠ” CUDA ë²„ì „ì…ë‹ˆë‹¤. CPU ë²„ì „ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."
                pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
                ;;
        esac
    else
        log_info "CPUìš© PyTorch ì„¤ì¹˜..."
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
    fi
    
    log_success "PyTorch ì„¤ì¹˜ ì™„ë£Œ"
}

# í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
install_dependencies() {
    log_info "í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘..."
    
    if [ ! -f "requirements.txt" ]; then
        log_error "requirements.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!"
        exit 1
    fi
    
    # í•µì‹¬ ì˜ì¡´ì„±ë§Œ ë¨¼ì € ì„¤ì¹˜
    log_info "í•µì‹¬ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘..."
    pip install transformers accelerate bitsandbytes
    
    # ë‚˜ë¨¸ì§€ ì˜ì¡´ì„± ì„¤ì¹˜
    log_info "ì¶”ê°€ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘..."
    pip install -r requirements.txt
    
    log_success "ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ"
}

# ì„¤ì¹˜ í™•ì¸
verify_installation() {
    log_info "ì„¤ì¹˜ í™•ì¸ ì¤‘..."
    
    python3 << 'EOF'
import sys
import torch
import transformers
import accelerate
import bitsandbytes

print("âœ… ì„¤ì¹˜ í™•ì¸ ê²°ê³¼:")
print(f"   Python: {sys.version}")
print(f"   PyTorch: {torch.__version__}")
print(f"   Transformers: {transformers.__version__}")
print(f"   Accelerate: {accelerate.__version__}")
print(f"   BitsAndBytes: {bitsandbytes.__version__}")

print(f"\nğŸ® GPU ì •ë³´:")
print(f"   CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"   CUDA ë²„ì „: {torch.version.cuda}")
    print(f"   GPU ê°œìˆ˜: {torch.cuda.device_count()}")
    print(f"   GPU ì´ë¦„: {torch.cuda.get_device_name()}")
    
    total_memory = torch.cuda.get_device_properties(0).total_memory
    print(f"   VRAM: {total_memory / 1024**3:.1f}GB")
    
    # ê°„ë‹¨í•œ CUDA í…ŒìŠ¤íŠ¸
    try:
        x = torch.tensor([1.0]).cuda()
        print(f"   CUDA í…ŒìŠ¤íŠ¸: ì„±ê³µ")
    except Exception as e:
        print(f"   CUDA í…ŒìŠ¤íŠ¸: ì‹¤íŒ¨ - {e}")
else:
    print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
EOF
    
    if [ $? -eq 0 ]; then
        log_success "ì„¤ì¹˜ í™•ì¸ ì™„ë£Œ"
    else
        log_error "ì„¤ì¹˜ í™•ì¸ ì‹¤íŒ¨"
        return 1
    fi
}

# í”„ë¡œì íŠ¸ íŒŒì¼ ê¶Œí•œ ì„¤ì •
setup_permissions() {
    log_info "íŒŒì¼ ê¶Œí•œ ì„¤ì • ì¤‘..."
    
    # Python íŒŒì¼ ì‹¤í–‰ ê¶Œí•œ
    find . -name "*.py" -exec chmod +x {} \;
    
    # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì‹¤í–‰ ê¶Œí•œ
    find . -name "*.sh" -exec chmod +x {} \;
    
    log_success "ê¶Œí•œ ì„¤ì • ì™„ë£Œ"
}

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
create_directories() {
    log_info "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘..."
    
    DIRECTORIES=(
        "model_cache"
        "logs"
        "outputs"
        "data"
        "experiments"
        "checkpoints"
    )
    
    for dir in "${DIRECTORIES[@]}"; do
        if [ ! -d "$dir" ]; then
            mkdir -p "$dir"
            log_info "ë””ë ‰í† ë¦¬ ìƒì„±: $dir"
        fi
    done
    
    log_success "ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ"
}

# ì„¤ì • íŒŒì¼ ìƒì„±
create_config() {
    log_info "ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
    
    if [ ! -f "config.yaml" ]; then
        python3 -c "
from config import config
config.save_to_yaml('config.yaml')
print('âœ… config.yaml ìƒì„± ì™„ë£Œ')
"
    else
        log_info "config.yamlì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
    fi
}

# ë©”ì¸ ì„¤ì¹˜ í•¨ìˆ˜
main_install() {
    echo "ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤..."
    echo "ì˜ˆìƒ ì†Œìš” ì‹œê°„: 10-20ë¶„"
    echo ""
    
    # ì„¤ì¹˜ ë‹¨ê³„ ì‹¤í–‰
    check_system
    update_system
    install_system_packages
    setup_nvidia
    setup_python_env
    install_pytorch
    install_dependencies
    setup_permissions
    create_directories
    verify_installation
    
    log_success "ğŸ‰ ì„¤ì¹˜ ì™„ë£Œ!"
    
    echo ""
    echo "================================================"
    echo "ğŸš€ ì‚¬ìš©ë²•:"
    echo "1. ê°€ìƒí™˜ê²½ í™œì„±í™”: source bllossom_env/bin/activate"
    echo "2. ì‹œìŠ¤í…œ í™•ì¸: python main.py --check"
    echo "3. ë°ëª¨ ì‹¤í–‰: python main.py --demo"
    echo "4. ì±„íŒ… ëª¨ë“œ: python main.py --chat"
    echo "5. CLI ë„ì›€ë§: python cli_interface.py --help"
    echo ""
    echo "ğŸ“š ì¶”ê°€ ì •ë³´:"
    echo "- ì„¤ì • íŒŒì¼: config.yaml"
    echo "- ë¡œê·¸ ë””ë ‰í† ë¦¬: logs/"
    echo "- ëª¨ë¸ ìºì‹œ: model_cache/"
    echo "================================================"
}

# ì¬ì‹œì‘ í›„ ì„¤ì¹˜ í•¨ìˆ˜
resume_install() {
    log_info "ì„¤ì¹˜ ì¬ê°œ ì¤‘..."
    setup_python_env
    install_pytorch
    install_dependencies
    verify_installation
    log_success "ì„¤ì¹˜ ì¬ê°œ ì™„ë£Œ!"
}

# ì¸ìˆ˜ ì²˜ë¦¬
case "${1:-}" in
    --resume)
        resume_install
        ;;
    --check)
        check_system
        setup_nvidia
        ;;
    --clean)
        log_info "ì„¤ì¹˜ íŒŒì¼ ì •ë¦¬ ì¤‘..."
        rm -rf bllossom_env model_cache logs outputs
        log_success "ì •ë¦¬ ì™„ë£Œ"
        ;;
    *)
        main_install
        ;;
esac
