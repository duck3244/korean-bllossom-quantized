# ğŸ“– Korean Bllossom AICA-5B ì‚¬ìš©ë²• ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Korean Bllossom AICA-5B ì–‘ìí™” í”„ë¡œì íŠ¸ì˜ ìƒì„¸í•œ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸš€ ì‹œì‘í•˜ê¸°

### ê¸°ë³¸ ì‹¤í–‰ ìˆœì„œ

```bash
# 1. ê°€ìƒí™˜ê²½ í™œì„±í™”
source bllossom_env/bin/activate

# 2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
python main.py --check

# 3. ì²« ì‹¤í–‰ (ë°ëª¨ ëª¨ë“œ)
python main.py --demo
```

## ğŸ¯ ì‹¤í–‰ ëª¨ë“œ

### 1. ëŒ€í™”í˜• ë©”ë‰´ ëª¨ë“œ

ê°€ì¥ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.

```bash
python main.py
```

**ë©”ë‰´ ì˜µì…˜**:
- `1`: ë°ëª¨ ëª¨ë“œ (ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸)
- `2`: ê°„ë‹¨ ì±„íŒ… ëª¨ë“œ
- `3`: CLI ëª¨ë“œ ì•ˆë‚´
- `4`: ì„¤ì • í™•ì¸
- `5`: ì‹œìŠ¤í…œ ì •ë³´
- `0`: ì¢…ë£Œ

### 2. ì§ì ‘ ì‹¤í–‰ ëª¨ë“œ

íŠ¹ì • ê¸°ëŠ¥ì„ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# ë°ëª¨ ëª¨ë“œ
python main.py --demo

# ì±„íŒ… ëª¨ë“œ
python main.py --chat

# ì‹œìŠ¤í…œ í™•ì¸
python main.py --check

# ì„¤ì • ì •ë³´
python main.py --config
```

## ğŸ’¬ í…ìŠ¤íŠ¸ ìƒì„± ì‚¬ìš©ë²•

### CLIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„±

#### ë‹¨ì¼ í…ìŠ¤íŠ¸ ìƒì„±

```bash
# ê¸°ë³¸ ì‚¬ìš©
python cli_interface.py text "í•œêµ­ì˜ ì „í†µë¬¸í™”ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"

# íŒŒë¼ë¯¸í„° ì¡°ì •
python cli_interface.py text "ì°½ì˜ì ì¸ ì´ì•¼ê¸°ë¥¼ ì¨ì£¼ì„¸ìš”" \
  --max-tokens 400 \
  --temperature 0.9 \
  --top-p 0.95
```

#### ëŒ€í™”í˜• ëª¨ë“œ

```bash
# ëŒ€í™”í˜• ì±„íŒ… ì‹œì‘
python cli_interface.py text --interactive

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì‹œì‘
python cli_interface.py text --interactive \
  --system-message "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ í•œêµ­ì–´ êµì‚¬ì…ë‹ˆë‹¤."
```

**ëŒ€í™”í˜• ëª¨ë“œ ëª…ë ¹ì–´**:
- `/help`: ë„ì›€ë§ í‘œì‹œ
- `/clear`: ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
- `/save`: ëŒ€í™”ë¥¼ íŒŒì¼ë¡œ ì €ì¥
- `/stats`: ëª¨ë¸ ìƒíƒœ ì •ë³´
- `/quit`: ì¢…ë£Œ

### Python API ì‚¬ìš©

#### ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±

```python
from config import Config
from model_manager import get_model_manager
from text_generator import TextGenerator

# ì´ˆê¸°í™”
config = Config()
manager = get_model_manager(config)
manager.load_model()
generator = TextGenerator(manager, config)

# í…ìŠ¤íŠ¸ ìƒì„±
result = generator.generate(
    prompt="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    max_tokens=300,
    temperature=0.7
)

if result["success"]:
    print(f"ì‘ë‹µ: {result['response']}")
    print(f"ìƒì„± ì‹œê°„: {result['generation_time']:.2f}ì´ˆ")
    print(f"ì†ë„: {result['tokens_per_second']:.1f} í† í°/ì´ˆ")
else:
    print(f"ì˜¤ë¥˜: {result['error']}")
```

#### ëŒ€í™” ê´€ë¦¬

```python
from text_generator import ConversationManager

# ëŒ€í™” ê´€ë¦¬ì ìƒì„±
conversation = ConversationManager(generator, max_history=10)

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
conversation.set_system_message(
    "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
)

# ëŒ€í™” ì‹œì‘
response1 = conversation.generate_response("ì•ˆë…•í•˜ì„¸ìš”!")
print(f"AI: {response1['response']}")

response2 = conversation.generate_response("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?")
print(f"AI: {response2['response']}")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸
summary = conversation.get_history_summary()
print(f"ëŒ€í™” ë©”ì‹œì§€ ìˆ˜: {summary['total_messages']}")

# ëŒ€í™” ì €ì¥
filename = conversation.export_conversation()
print(f"ëŒ€í™” ì €ì¥ë¨: {filename}")
```

#### ë°°ì¹˜ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ì¼ê´„ ì²˜ë¦¬
prompts = [
    "íŒŒì´ì¬ì˜ ì¥ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì˜ ë¯¸ë˜ëŠ” ì–´ë–¨ê¹Œìš”?"
]

results = generator.batch_generate(
    prompts, 
    max_tokens=200, 
    temperature=0.6
)

for i, result in enumerate(results):
    if result["success"]:
        print(f"ì§ˆë¬¸ {i+1}: {prompts[i]}")
        print(f"ë‹µë³€: {result['response']}\n")
```

## ğŸ–¼ï¸ ì‹œê°-ì–¸ì–´ ëª¨ë¸ ì‚¬ìš©ë²•

### CLIë¥¼ í†µí•œ ì´ë¯¸ì§€ ë¶„ì„

#### ì´ë¯¸ì§€ ì„¤ëª…

```bash
# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼
python cli_interface.py vision image.jpg --task describe

# ì›¹ ì´ë¯¸ì§€ URL
python cli_interface.py vision "https://example.com/image.jpg" --task describe

# ìƒì„¸ ì„¤ëª… ìš”ì²­
python cli_interface.py vision photo.png --task describe \
  --max-tokens 400 --temperature 0.1
```

#### OCR (í…ìŠ¤íŠ¸ ì¶”ì¶œ)

```bash
# ë¬¸ì„œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
python cli_interface.py vision document.png --task ocr

# ëª…í•¨ì´ë‚˜ ê°„íŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ
python cli_interface.py vision business_card.jpg --task ocr \
  --output extracted_text.txt
```

#### ì°¨íŠ¸ ë° í‘œ ë¶„ì„

```bash
# ì°¨íŠ¸ ë¶„ì„
python cli_interface.py vision chart.png --task chart

# í‘œ ë°ì´í„° ì¶”ì¶œ
python cli_interface.py vision table.jpg --task table

# ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
python cli_interface.py vision document.png --task markdown \
  --output document.md
```

#### ì‹œê°ì  ì§ˆë¬¸ë‹µë³€

```bash
# ì´ë¯¸ì§€ì— ëŒ€í•œ êµ¬ì²´ì  ì§ˆë¬¸
python cli_interface.py vision photo.jpg --task qa \
  --prompt "ì´ ì‚¬ì§„ì—ì„œ ì‚¬ëŒì´ ëª‡ ëª… ë³´ì´ë‚˜ìš”?"

# ë³µì¡í•œ ë¶„ì„ ìš”ì²­
python cli_interface.py vision scene.jpg --task qa \
  --prompt "ì´ ì¥ë©´ì˜ ë¶„ìœ„ê¸°ì™€ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”" \
  --max-tokens 300
```

### Python APIë¥¼ í†µí•œ ì´ë¯¸ì§€ ì²˜ë¦¬

#### ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„

```python
from vision_generator import VisionGenerator

# ì‹œê°-ì–¸ì–´ ìƒì„±ê¸° ì´ˆê¸°í™”
vision_gen = VisionGenerator(manager, config)

# ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
result = vision_gen.describe_image("path/to/image.jpg")
if result["success"]:
    print(f"ì´ë¯¸ì§€ ì„¤ëª…: {result['response']}")

# OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
ocr_result = vision_gen.extract_text("document.png")
if ocr_result["success"]:
    print(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {ocr_result['response']}")

# ì°¨íŠ¸ ë¶„ì„
chart_result = vision_gen.analyze_chart("sales_chart.png")
print(f"ì°¨íŠ¸ ë¶„ì„: {chart_result['response']}")
```

#### ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹

```python
from PIL import Image
import requests

# 1. ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
result1 = vision_gen.describe_image("./images/photo.jpg")

# 2. URL
result2 = vision_gen.describe_image("https://example.com/image.png")

# 3. PIL Image ê°ì²´
image = Image.open("photo.jpg")
result3 = vision_gen.describe_image(image)

# 4. ë°”ì´íŠ¸ ë°ì´í„°
with open("image.jpg", "rb") as f:
    image_bytes = f.read()
result4 = vision_gen.describe_image(image_bytes)

# 5. Base64 ë°ì´í„° URL
import base64
with open("image.jpg", "rb") as f:
    encoded = base64.b64encode(f.read()).decode()
    data_url = f"data:image/jpeg;base64,{encoded}"
result5 = vision_gen.describe_image(data_url)
```

#### ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸

```python
# ë§ì¶¤í˜• ì´ë¯¸ì§€ ë¶„ì„
custom_result = vision_gen.generate_with_image(
    image="product_photo.jpg",
    prompt="ì´ ì œí’ˆì˜ íŠ¹ì§•ê³¼ ì¥ë‹¨ì ì„ ë§ˆì¼€íŒ… ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”",
    max_tokens=400,
    temperature=0.3
)

# ì „ë¬¸ì ì¸ ë¶„ì„
medical_result = vision_gen.generate_with_image(
    image="xray.jpg",
    prompt="ì´ ì˜ë£Œ ì´ë¯¸ì§€ì—ì„œ ì£¼ëª©í•  ë§Œí•œ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš” (ì°¸ê³ ìš©)",
    max_tokens=200,
    temperature=0.1
)
```

#### ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì²˜ë¦¬
image_files = [
    "photo1.jpg",
    "photo2.jpg", 
    "photo3.jpg"
]

batch_results = vision_gen.batch_analyze_images(
    image_files,
    prompt="ì´ ì´ë¯¸ì§€ë“¤ì˜ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
    max_tokens=250
)

for i, result in enumerate(batch_results):
    if result["success"]:
        print(f"ì´ë¯¸ì§€ {i+1} ë¶„ì„: {result['response']}")
```

## ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ ì‚¬ìš©ë²•

### CLIë¥¼ í†µí•œ ë¬¸ì„œ ì²˜ë¦¬

#### ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬

```bash
# í…ìŠ¤íŠ¸ ì¶”ì¶œ
python cli_interface.py document scan.png --task extract

# ë¬¸ì„œ ìš”ì•½
python cli_interface.py document report.jpg --task summarize

# ë§ˆí¬ë‹¤ìš´ ë³€í™˜
python cli_interface.py document page.png --task markdown \
  --output converted.md

# í‘œ ë°ì´í„° ì¶”ì¶œ
python cli_interface.py document table_image.png --task table
```

#### ë‹¤ì¤‘ í˜ì´ì§€ ë¬¸ì„œ

```bash
# í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
python cli_interface.py document ./document_pages/ \
  --task extract --multi-page --output full_document.txt

# ì—¬ëŸ¬ íŒŒì¼ ì§€ì •
python cli_interface.py document "page1.png,page2.png,page3.png" \
  --task markdown --multi-page
```

### Python APIë¥¼ í†µí•œ ë¬¸ì„œ ì²˜ë¦¬

#### ë¬¸ì„œ ì²˜ë¦¬ê¸° ì‚¬ìš©

```python
from vision_generator import DocumentProcessor

# ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
doc_processor = DocumentProcessor(vision_gen)

# ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬
result = doc_processor.process_document_page(
    "contract.png",
    task="extract"  # extract, summarize, markdown, table
)

if result["success"]:
    print(f"ë¬¸ì„œ ë‚´ìš©: {result['response']}")
```

#### ë‹¤ì¤‘ í˜ì´ì§€ ë¬¸ì„œ ì²˜ë¦¬

```python
import os

# ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
def get_image_files(directory):
    supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.webp')
    files = []
    for file in sorted(os.listdir(directory)):
        if file.lower().endswith(supported_formats):
            files.append(os.path.join(directory, file))
    return files

# ë‹¤ì¤‘ í˜ì´ì§€ ì²˜ë¦¬
image_files = get_image_files("./scanned_document/")
result = doc_processor.process_multi_page_document(
    image_files,
    task="markdown"
)

print(f"ì²˜ë¦¬ëœ í˜ì´ì§€ ìˆ˜: {result['total_pages']}")
print(f"ì„±ê³µí•œ í˜ì´ì§€ ìˆ˜: {result['successful_pages']}")
print(f"ì „ì²´ ë‚´ìš©:\n{result['combined_content']}")

# ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
with open("processed_document.md", "w", encoding="utf-8") as f:
    f.write(result['combined_content'])
```

## ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‚¬ìš©ë²•

### í…ìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬

#### í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ì½ê¸°

```bash
# prompts.txt íŒŒì¼ ìƒì„±
echo "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”" > prompts.txt
echo "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?" >> prompts.txt
echo "í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?" >> prompts.txt

# ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
python cli_interface.py batch prompts.txt --output results.json
```

#### JSON í˜•ì‹ ë°°ì¹˜ ì²˜ë¦¬

```json
// batch_tasks.json
[
  {
    "prompt": "í•œêµ­ì˜ ì „í†µìŒì‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "max_tokens": 200,
    "temperature": 0.7
  },
  {
    "prompt": "K-POPì˜ ì„¸ê³„ì  ì¸ê¸° ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "max_tokens": 250,
    "temperature": 0.6
  },
  {
    "image": "chart.png",
    "prompt": "ì´ ì°¨íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
    "max_tokens": 300
  }
]
```

```bash
# JSON ë°°ì¹˜ ì²˜ë¦¬
python cli_interface.py batch batch_tasks.json --output detailed_results.json
```

### Python APIë¥¼ í†µí•œ ë°°ì¹˜ ì²˜ë¦¬

```python
import json
from datetime import datetime

# ë°°ì¹˜ ì‘ì—… ì •ì˜
batch_tasks = [
    {
        "type": "text",
        "prompt": "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ",
        "params": {"max_tokens": 200, "temperature": 0.5}
    },
    {
        "type": "vision",
        "image": "diagram.png",
        "prompt": "ì´ ë‹¤ì´ì–´ê·¸ë¨ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "params": {"max_tokens": 250}
    }
]

# ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
results = []
for i, task in enumerate(batch_tasks):
    print(f"ì‘ì—… {i+1}/{len(batch_tasks)} ì²˜ë¦¬ ì¤‘...")
    
    if task["type"] == "text":
        result = generator.generate(
            task["prompt"],
            **task.get("params", {})
        )
    elif task["type"] == "vision":
        result = vision_gen.generate_with_image(
            task["image"],
            task["prompt"],
            **task.get("params", {})
        )
    
    results.append({
        "task_id": i,
        "task": task,
        "result": result,
        "timestamp": datetime.now().isoformat()
    })
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    manager.clear_memory()

# ê²°ê³¼ ì €ì¥
with open("batch_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì‘ì—…")
```

## âš™ï¸ ê³ ê¸‰ ì„¤ì • ë° ìµœì í™”

### ì„±ëŠ¥ íŒŒë¼ë¯¸í„° ì¡°ì •

#### ìƒì„± í’ˆì§ˆ vs ì†ë„ ê· í˜•

```python
# ê³ í’ˆì§ˆ ëª¨ë“œ (ëŠë¦¼)
high_quality_params = {
    "max_tokens": 400,
    "temperature": 0.3,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1
}

# ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ (í’ˆì§ˆ íƒ€í˜‘)
fast_response_params = {
    "max_tokens": 150,
    "temperature": 0.1,
    "do_sample": False
}

# ì°½ì˜ì  ëª¨ë“œ (ë‹¤ì–‘í•œ ì‘ë‹µ)
creative_params = {
    "max_tokens": 300,
    "temperature": 0.9,
    "top_p": 0.95,
    "do_sample": True
}
```

#### ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •

```python
# config.yaml ìˆ˜ì •
generation:
  max_tokens: 200        # í† í° ìˆ˜ ì œí•œ
  use_cache: false       # ìºì‹œ ë¹„í™œì„±í™”
  
hardware:
  max_memory_usage: 0.85 # VRAM 85%ê¹Œì§€ë§Œ ì‚¬ìš©
  
quantization:
  load_in_4bit: true     # 4ë¹„íŠ¸ ì–‘ìí™” í™œì„±í™”
```

### ì‹œìŠ¤í…œ ë©”ì‹œì§€ í™œìš©

#### ì—­í•  ê¸°ë°˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€

```python
# ì „ë¬¸ê°€ ì—­í• 
expert_messages = {
    "teacher": "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” êµì‚¬ì…ë‹ˆë‹¤.",
    "translator": "ë‹¹ì‹ ì€ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.",
    "writer": "ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ë§¤ë ¥ì ì¸ ê¸€ì„ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤.",
    "analyst": "ë‹¹ì‹ ì€ ë°ì´í„°ë¥¼ ì •í™•í•˜ê²Œ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤."
}

# ëŒ€í™” ìŠ¤íƒ€ì¼ ì„¤ì •
conversation.set_system_message(expert_messages["teacher"])
```

#### ì¶œë ¥ í˜•ì‹ ì§€ì •

```python
# êµ¬ì¡°í™”ëœ ì¶œë ¥ ìš”ì²­
structured_prompt = """
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

## ìš”ì•½
- í•µì‹¬ ë‚´ìš© 3ê°€ì§€

## ìƒì„¸ ì„¤ëª…
- ê° í•­ëª©ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…

## ê²°ë¡ 
- ìµœì¢… ìš”ì•½ ë° ì œì–¸

ì§ˆë¬¸: {user_question}
"""

result = generator.generate(
    structured_prompt.format(user_question="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜"),
    max_tokens=400
)
```

### ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„

```python
import time

def robust_generate(generator, prompt, max_retries=3):
    """ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ í¬í•¨í•œ ì•ˆì •ì ì¸ ìƒì„± í•¨ìˆ˜"""
    
    for attempt in range(max_retries):
        try:
            result = generator.generate(prompt)
            
            if result["success"]:
                return result
            else:
                print(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {result['error']}")
                
        except Exception as e:
            print(f"ì‹œë„ {attempt + 1} ì˜ˆì™¸ ë°œìƒ: {e}")
            
        # ì¬ì‹œë„ ì „ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ëŒ€ê¸°
        generator.model_manager.clear_memory()
        time.sleep(2)
    
    return {"success": False, "error": "ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨"}

# ì‚¬ìš© ì˜ˆì‹œ
result = robust_generate(generator, "ë³µì¡í•œ ì§ˆë¬¸")
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
import time
import psutil

class PerformanceMonitor:
    def __init__(self, model_manager):
        self.model_manager = model_manager
        self.start_time = None
        
    def start_monitoring(self):
        self.start_time = time.time()
        print("ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
    def log_performance(self, operation_name):
        if self.start_time:
            elapsed = time.time() - self.start_time
            
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.memory_allocated() / 1024**3
                gpu_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                gpu_usage = (gpu_memory / gpu_total) * 100
            else:
                gpu_memory = gpu_usage = 0
                
            # CPU ë° RAM ì‚¬ìš©ëŸ‰
            cpu_usage = psutil.cpu_percent()
            ram = psutil.virtual_memory()
            
            print(f"ğŸ“Š {operation_name} ì„±ëŠ¥:")
            print(f"   ì‹¤í–‰ ì‹œê°„: {elapsed:.2f}ì´ˆ")
            print(f"   GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB ({gpu_usage:.1f}%)")
            print(f"   CPU ì‚¬ìš©ë¥ : {cpu_usage:.1f}%")
            print(f"   RAM ì‚¬ìš©ë¥ : {ram.percent:.1f}%")

# ì‚¬ìš© ì˜ˆì‹œ
monitor = PerformanceMonitor(manager)
monitor.start_monitoring()

result = generator.generate("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")
monitor.log_performance("í…ìŠ¤íŠ¸ ìƒì„±")
```

### ë¡œê·¸ íŒŒì¼ ê´€ë¦¬

```python
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ìƒì„¸ ë¡œê¹… ì„¤ì •"""
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("logs", exist_ok=True)
    
    # ë¡œê·¸ í¬ë§· ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¼ë³„ ë¡œê·¸ íŒŒì¼)
    today = datetime.now().strftime("%Y%m%d")
    file_handler = logging.FileHandler(f"logs/bllossom_{today}.log")
    file_handler.setFormatter(formatter)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# ì‚¬ìš© ì˜ˆì‹œ
logger = setup_logging()

logger.info("í”„ë¡œê·¸ë¨ ì‹œì‘")
logger.info(f"ëª¨ë¸ ë¡œë”©: {config.model.name}")

try:
    result = generator.generate("í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸")
    logger.info(f"ìƒì„± ì„±ê³µ: {result['tokens_per_second']:.1f} t/s")
except Exception as e:
    logger.error(f"ìƒì„± ì‹¤íŒ¨: {e}")
```

## ğŸ¨ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

### 1. êµìœ¡ ì½˜í…ì¸  ìƒì„±

```python
def create_educational_content(topic, grade_level="ì¤‘í•™ìƒ"):
    """êµìœ¡ìš© ì½˜í…ì¸  ìƒì„±"""
    
    prompt = f"""
{grade_level} ìˆ˜ì¤€ì— ë§ê²Œ '{topic}'ì— ëŒ€í•œ í•™ìŠµ ìë£Œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ê°œë… ì„¤ëª… (ì‰¬ìš´ ì–¸ì–´ë¡œ)
2. ì‹¤ìƒí™œ ì˜ˆì‹œ 3ê°€ì§€
3. ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ë°©ë²•
4. ê°„ë‹¨í•œ í€´ì¦ˆ ë¬¸ì œ 2ê°œ

ê¸¸ì´: 300-400ë‹¨ì–´
"""
    
    result = generator.generate(prompt, max_tokens=500, temperature=0.6)
    return result['response'] if result['success'] else None

# ì‚¬ìš© ì˜ˆì‹œ
content = create_educational_content("ê´‘í•©ì„±", "ì´ˆë“±í•™ìƒ")
print(content)
```

### 2. ë¬¸ì„œ ìë™ ìš”ì•½

```python
def summarize_document(document_text, summary_type="executive"):
    """ë¬¸ì„œ ìë™ ìš”ì•½"""
    
    summary_prompts = {
        "executive": "ë‹¤ìŒ ë¬¸ì„œë¥¼ ê²½ì˜ì§„ì„ ìœ„í•œ ìš”ì•½ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš” (3-5ì¤„):",
        "detailed": "ë‹¤ìŒ ë¬¸ì„œì˜ ìƒì„¸í•œ ìš”ì•½ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš” (10-15ì¤„):",
        "bullet": "ë‹¤ìŒ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:"
    }
    
    prompt = f"{summary_prompts[summary_type]}\n\n{document_text}"
    
    result = generator.generate(
        prompt, 
        max_tokens=300, 
        temperature=0.3
    )
    
    return result['response'] if result['success'] else None

# ì‚¬ìš© ì˜ˆì‹œ
with open("report.txt", "r", encoding="utf-8") as f:
    document = f.read()

summary = summarize_document(document, "executive")
print(f"ìš”ì•½:\n{summary}")
```

### 3. ë‹¤êµ­ì–´ ë²ˆì—­

```python
def translate_text(text, target_language="ì˜ì–´"):
    """í…ìŠ¤íŠ¸ ë²ˆì—­"""
    
    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {target_language}ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”:

ì›ë¬¸: {text}

ë²ˆì—­í•  ë•Œ ë‹¤ìŒì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
- ë¬¸ë§¥ê³¼ ë‰˜ì•™ìŠ¤ ìœ ì§€
- ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
- ë¬¸í™”ì  ì°¨ì´ ê³ ë ¤

ë²ˆì—­:
"""
    
    result = generator.generate(prompt, max_tokens=200, temperature=0.3)
    return result['response'] if result['success'] else None

# ì‚¬ìš© ì˜ˆì‹œ
korean_text = "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. ì‚°ì±…í•˜ê¸° ë”± ì¢‹ì€ ë‚ ì”¨ì…ë‹ˆë‹¤."
english_translation = translate_text(korean_text, "ì˜ì–´")
print(f"ë²ˆì—­: {english_translation}")
```

### 4. ì°½ì‘ ì§€ì› ë„êµ¬

```python
def creative_writing_assistant(genre, theme, length="short"):
    """ì°½ì‘ ì§€ì› ë„êµ¬"""
    
    length_guide = {
        "short": "200-300ë‹¨ì–´ì˜ ì§§ì€",
        "medium": "500-700ë‹¨ì–´ì˜ ì¤‘ê°„ ê¸¸ì´",
        "long": "1000ë‹¨ì–´ ì´ìƒì˜ ê¸´"
    }
    
    prompt = f"""
ë‹¤ìŒ ì¡°ê±´ìœ¼ë¡œ {length_guide[length]} {genre} ì‘í’ˆì„ ì¨ì£¼ì„¸ìš”:

ì¥ë¥´: {genre}
ì£¼ì œ: {theme}

ì‘í’ˆ ìš”êµ¬ì‚¬í•­:
- í¥ë¯¸ì§„ì§„í•˜ê³  ë…ì°½ì ì¸ ë‚´ìš©
- ìƒìƒí•œ ë¬˜ì‚¬ì™€ ëŒ€í™”
- ëª…í™•í•œ ì‹œì‘, ì „ê°œ, ê²°ë§
- ì½ëŠ” ì¬ë¯¸ê°€ ìˆëŠ” ë¬¸ì²´

ì‘í’ˆ:
"""
    
    max_tokens = {"short": 400, "medium": 800, "long": 1200}[length]
    
    result = generator.generate(
        prompt, 
        max_tokens=max_tokens, 
        temperature=0.8
    )
    
    return result['response'] if result['success'] else None

# ì‚¬ìš© ì˜ˆì‹œ
story = creative_writing_assistant("SF ì†Œì„¤", "ì‹œê°„ ì—¬í–‰", "medium")
print(f"ì°½ì‘ ì†Œì„¤:\n{story}")
```

---

## ğŸ’¡ ì‚¬ìš© íŒ

### íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±ë²•

1. **êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ**: ëª¨í˜¸í•œ ì§ˆë¬¸ë³´ë‹¤ëŠ” êµ¬ì²´ì ì¸ ìš”ì²­
2. **ì˜ˆì‹œ ì œê³µ**: ì›í•˜ëŠ” í˜•ì‹ì´ë‚˜ ìŠ¤íƒ€ì¼ì˜ ì˜ˆì‹œ í¬í•¨
3. **ë‹¨ê³„ë³„ ìš”ì²­**: ë³µì¡í•œ ì‘ì—…ì€ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ìš”ì²­
4. **ì œì•½ ì¡°ê±´ ëª…ì‹œ**: ê¸¸ì´, í˜•ì‹, í†¤ ë“±ì˜ ì œì•½ ì¡°ê±´ ëª…ì‹œ

### ì„±ëŠ¥ ìµœì í™” ìš”ë ¹

1. **ì ì ˆí•œ í† í° ìˆ˜**: í•„ìš”í•œ ë§Œí¼ë§Œ ìƒì„±í•˜ì—¬ ì†ë„ í–¥ìƒ
2. **ì˜¨ë„ ì¡°ì ˆ**: ì¼ê´€ëœ ê²°ê³¼ê°€ í•„ìš”í•˜ë©´ ë‚®ì€ ì˜¨ë„ ì‚¬ìš©
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: í° ì‘ì—… í›„ì—ëŠ” ë©”ëª¨ë¦¬ ì •ë¦¬
4. **ë°°ì¹˜ í¬ê¸°**: í•œ ë²ˆì— ë„ˆë¬´ ë§ì€ ì‘ì—… í”¼í•˜ê¸°

### ë¬¸ì œ ë°œìƒ ì‹œ ëŒ€ì²˜ë²•

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë” ì‘ì€ ë°°ì¹˜ í¬ê¸°ë‚˜ í† í° ìˆ˜ ì‚¬ìš©
2. **ëŠë¦° ì‘ë‹µ**: ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸, ìºì‹œ ì •ë¦¬
3. **í’ˆì§ˆ ì €í•˜**: í”„ë¡¬í”„íŠ¸ ê°œì„ , íŒŒë¼ë¯¸í„° ì¡°ì •
4. **ì˜¤ë¥˜ ë°œìƒ**: ë¡œê·¸ í™•ì¸, ì¬ì‹œì‘ ì‹œë„

ì´ ê°€ì´ë“œë¥¼ í†µí•´ Korean Bllossom AICA-5B ëª¨ë¸ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤!