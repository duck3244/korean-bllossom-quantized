# main.py (ìˆ˜ì •ëœ ë²„ì „)
# Korean Bllossom AICA-5B ë©”ì¸ ì‹¤í–‰ íŒŒì¼
# Import ê²½ë¡œ ë¬¸ì œ í•´ê²°

import sys
import os
import argparse
import warnings

warnings.filterwarnings('ignore')

from core.config import Config, setup_environment
from core.model_manager import get_model_manager
from core.text_generator import TextGenerator, ConversationManager
from core.vision_generator import VisionGenerator, DocumentProcessor

def demo_mode():
    """ë°ëª¨ ëª¨ë“œ - ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸŒ¸ Korean Bllossom AICA-5B ë°ëª¨ ëª¨ë“œ")
    print("=" * 60)

    try:
        # í™˜ê²½ ì„¤ì •
        setup_environment()

        # ì„¤ì • ë¡œë“œ
        config = Config()
        config.print_config()

        # ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        print("\nğŸš€ ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        model_manager = get_model_manager(config)

        if not model_manager.load_model():
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨! ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return False

        # í…ìŠ¤íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        text_generator = TextGenerator(model_manager, config)
        vision_generator = VisionGenerator(model_manager, config)

        print("\n" + "=" * 60)
        print("ğŸ§ª ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        # 1. í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ“ í…ŒìŠ¤íŠ¸ 1: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìƒì„±")
        print("-" * 30)

        result1 = text_generator.generate(
            "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            max_tokens=150,
            temperature=0.7
        )

        if result1["success"]:
            print(f"âœ… ì„±ê³µ! ì‘ë‹µ: {result1['response']}")
            print(f"ğŸ“Š ì†ë„: {result1['tokens_per_second']:.1f} í† í°/ì´ˆ")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result1['error']}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        model_manager.clear_memory()

        # 2. ì˜ì–´ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ“ í…ŒìŠ¤íŠ¸ 2: ì˜ì–´ í…ìŠ¤íŠ¸ ìƒì„±")
        print("-" * 30)

        result2 = text_generator.generate(
            "What are the main benefits of using AI in healthcare?",
            max_tokens=120,
            temperature=0.6
        )

        if result2["success"]:
            print(f"âœ… ì„±ê³µ! ì‘ë‹µ: {result2['response']}")
            print(f"ğŸ“Š ì†ë„: {result2['tokens_per_second']:.1f} í† í°/ì´ˆ")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result2['error']}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        model_manager.clear_memory()

        # 3. ëŒ€í™” ëª¨ë“œ í…ŒìŠ¤íŠ¸
        print("\nğŸ’¬ í…ŒìŠ¤íŠ¸ 3: ëŒ€í™” ëª¨ë“œ")
        print("-" * 30)

        conversation = ConversationManager(text_generator, max_history=4)
        conversation.set_system_message("ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")

        # ì²« ë²ˆì§¸ ëŒ€í™”
        conv_result1 = conversation.generate_response(
            "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?",
            max_tokens=100,
            temperature=0.8
        )

        if conv_result1["success"]:
            print(f"ì‚¬ìš©ì: ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?")
            print(f"AI: {conv_result1['response']}")

        # ë‘ ë²ˆì§¸ ëŒ€í™”
        conv_result2 = conversation.generate_response(
            "ê·¸ëŸ¼ ì‹¤ë‚´ì—ì„œ í•  ìˆ˜ ìˆëŠ” í™œë™ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.",
            max_tokens=100,
            temperature=0.8
        )

        if conv_result2["success"]:
            print(f"ì‚¬ìš©ì: ê·¸ëŸ¼ ì‹¤ë‚´ì—ì„œ í•  ìˆ˜ ìˆëŠ” í™œë™ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.")
            print(f"AI: {conv_result2['response']}")

        # ëŒ€í™” ìš”ì•½
        summary = conversation.get_history_summary()
        print(f"ğŸ“‹ ëŒ€í™” ìš”ì•½: {summary['total_messages']}ê°œ ë©”ì‹œì§€")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        model_manager.clear_memory()

        # 4. ì‹œê°-ì–¸ì–´ í…ŒìŠ¤íŠ¸ (ì˜µì…˜)
        print("\nğŸ–¼ï¸ í…ŒìŠ¤íŠ¸ 4: ì‹œê°-ì–¸ì–´ ëª¨ë¸ (ì„ íƒì )")
        print("-" * 30)

        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ (React ë¡œê³ )
            test_image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/React-icon.svg/1200px-React-icon.svg.png"

            vision_result = vision_generator.describe_image(test_image_url)

            if vision_result["success"]:
                print(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì„±ê³µ!")
                print(f"ğŸ–¼ï¸ ì‘ë‹µ: {vision_result['response']}")
                print(f"ğŸ“Š ì†ë„: {vision_result['tokens_per_second']:.1f} í† í°/ì´ˆ")
            else:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {vision_result['error']}")

        except Exception as e:
            print(f"âš ï¸ ì‹œê°-ì–¸ì–´ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°: {e}")

        # ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬
        model_manager.clear_memory()

        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
        model_manager._print_memory_usage()

        return True

    except Exception as e:
        print(f"\nâŒ ë°ëª¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # ëª¨ë¸ ì–¸ë¡œë“œ
        if 'model_manager' in locals():
            model_manager.unload_model()


def simple_chat_mode():
    """ê°„ë‹¨í•œ ì±„íŒ… ëª¨ë“œ"""
    print("ğŸ’¬ Korean Bllossom ê°„ë‹¨ ì±„íŒ… ëª¨ë“œ")
    print("=" * 40)
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', 'ì¢…ë£Œ' ì…ë ¥")
    print("-" * 40)

    try:
        # í™˜ê²½ ì„¤ì •
        setup_environment()
        config = Config()

        # ëª¨ë¸ ì´ˆê¸°í™”
        model_manager = get_model_manager(config)
        if not model_manager.load_model():
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!")
            return

        text_generator = TextGenerator(model_manager, config)
        conversation = ConversationManager(text_generator)
        conversation.set_system_message("ë‹¹ì‹ ì€ í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ì˜í•˜ëŠ” ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")

        while True:
            try:
                user_input = input("\nì‚¬ìš©ì: ").strip()

                if not user_input:
                    continue

                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                    print("ğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                result = conversation.generate_response(
                    user_input,
                    max_tokens=200,
                    temperature=0.7
                )

                if result["success"]:
                    print(f"AI: {result['response']}")
                else:
                    print(f"âŒ ì˜¤ë¥˜: {result['error']}")

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                model_manager.clear_memory()

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")

    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

    finally:
        if 'model_manager' in locals():
            model_manager.unload_model()


def interactive_menu():
    """ëŒ€í™”í˜• ë©”ë‰´"""
    while True:
        print("\nğŸŒ¸ Korean Bllossom AICA-5B")
        print("=" * 30)
        print("1. ë°ëª¨ ëª¨ë“œ (ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸)")
        print("2. ê°„ë‹¨ ì±„íŒ… ëª¨ë“œ")
        print("3. CLI ëª¨ë“œ")
        print("4. ì„¤ì • í™•ì¸")
        print("5. ì‹œìŠ¤í…œ ì •ë³´")
        print("0. ì¢…ë£Œ")
        print("-" * 30)

        try:
            choice = input("ì„ íƒí•˜ì„¸ìš” (0-5): ").strip()

            if choice == '0':
                print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            elif choice == '1':
                demo_mode()
            elif choice == '2':
                simple_chat_mode()
            elif choice == '3':
                print("\nCLI ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰í•˜ì„¸ìš”:")
                print("python cli_interface.py --help")
                print("ì˜ˆ: python cli_interface.py text --interactive")
            elif choice == '4':
                show_config()
            elif choice == '5':
                show_system_info()
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")


def show_config():
    """ì„¤ì • ì •ë³´ í‘œì‹œ"""
    print("\nâš™ï¸ í˜„ì¬ ì„¤ì •")
    print("-" * 20)

    try:
        config = Config()
        config.print_config()

        print(f"\nğŸ“ ê²½ë¡œ ì„¤ì •:")
        print(f"   ìºì‹œ ë””ë ‰í† ë¦¬: {config.paths.cache_dir}")
        print(f"   ë¡œê·¸ ë””ë ‰í† ë¦¬: {config.paths.log_dir}")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {config.paths.output_dir}")
    except Exception as e:
        print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")


def show_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ"""
    print("\nğŸ’» ì‹œìŠ¤í…œ ì •ë³´")
    print("-" * 20)

    try:
        import torch
        import psutil
        import platform

        print(f"OS: {platform.system()} {platform.release()}")
        print(f"Python: {platform.python_version()}")
        print(f"PyTorch: {torch.__version__}")

        # CPU ì •ë³´
        cpu_count = psutil.cpu_count()
        ram_gb = psutil.virtual_memory().total / (1024 ** 3)
        print(f"CPU: {cpu_count}ì½”ì–´")
        print(f"RAM: {ram_gb:.1f}GB")

        # GPU ì •ë³´
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name()
            total_vram = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
            print(f"GPU: {gpu_name}")
            print(f"VRAM: {total_vram:.1f}GB")
            print(f"CUDA: {torch.version.cuda}")
        else:
            print("GPU: CUDA ì‚¬ìš© ë¶ˆê°€")

        # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
        print(f"\nğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸:")

        packages_to_check = [
            ('transformers', 'transformers'),
            ('accelerate', 'accelerate'),
            ('bitsandbytes', 'bitsandbytes'),
            ('config', 'config'),
            ('model_manager', 'model_manager'),
            ('text_generator', 'text_generator'),
            ('vision_generator', 'vision_generator')
        ]

        for package_name, import_name in packages_to_check:
            try:
                module = __import__(import_name)
                version = getattr(module, '__version__', 'Unknown')
                print(f"   âœ… {package_name}: {version}")
            except ImportError:
                print(f"   âŒ {package_name}: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")


def check_requirements():
    """í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
    print("ğŸ” ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...")

    issues = []

    try:
        # Python ë²„ì „ í™•ì¸
        if sys.version_info < (3, 8):
            issues.append("Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # PyTorch ë° CUDA í™•ì¸
        try:
            import torch
            if not torch.cuda.is_available():
                issues.append("CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                total_vram = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
                if total_vram < 6:
                    issues.append(f"VRAMì´ {total_vram:.1f}GBë¡œ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¶Œì¥: 8GB ì´ìƒ)")
        except ImportError:
            issues.append("PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        # required_files = ['config.py', 'model_manager.py', 'text_generator.py', 'vision_generator.py']
        # for file in required_files:
        #     if not os.path.exists(file):
        #         issues.append(f"í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file}")

        # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
        required_packages = ['transformers', 'accelerate', 'bitsandbytes']
        for package in required_packages:
            try:
                __import__(package)
            except ImportError:
                issues.append(f"{package} íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ë©”ëª¨ë¦¬ í™•ì¸
        import psutil
        ram_gb = psutil.virtual_memory().total / (1024 ** 3)
        if ram_gb < 16:
            issues.append(f"RAMì´ {ram_gb:.1f}GBë¡œ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¶Œì¥: 32GB ì´ìƒ)")

        if issues:
            print("\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in issues:
                print(f"   - {issue}")
            print("\nğŸ’¡ ì„¤ì¹˜ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”.")
            return False
        else:
            print("âœ… ëª¨ë“  ìš”êµ¬ì‚¬í•­ì´ ì¶©ì¡±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True

    except Exception as e:
        print(f"âŒ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="Korean Bllossom AICA-5B í”„ë¡œì íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‹¤í–‰ ëª¨ë“œ:
  --demo      : ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ê¸°ë³¸ê°’)
  --chat      : ê°„ë‹¨í•œ ì±„íŒ… ëª¨ë“œ
  --check     : ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
  --config    : ì„¤ì • ì •ë³´ í‘œì‹œ
  --info      : ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ

ì˜ˆì œ:
  python main.py                 # ëŒ€í™”í˜• ë©”ë‰´
  python main.py --demo          # ë°ëª¨ ëª¨ë“œ
  python main.py --chat          # ì±„íŒ… ëª¨ë“œ
  python main.py --check         # ìš”êµ¬ì‚¬í•­ í™•ì¸
        """
    )

    parser.add_argument('--demo', action='store_true', help='ë°ëª¨ ëª¨ë“œ ì‹¤í–‰')
    parser.add_argument('--chat', action='store_true', help='ì±„íŒ… ëª¨ë“œ ì‹¤í–‰')
    parser.add_argument('--check', action='store_true', help='ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸')
    parser.add_argument('--config', action='store_true', help='ì„¤ì • ì •ë³´ í‘œì‹œ')
    parser.add_argument('--info', action='store_true', help='ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ')
    parser.add_argument('--config-file', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')

    args = parser.parse_args()

    try:
        # í™˜ê²½ ì„¤ì •
        if 'setup_environment' in globals():
            setup_environment()

        # ëª¨ë“œë³„ ì‹¤í–‰
        if args.check:
            check_requirements()
        elif args.config:
            show_config()
        elif args.info:
            show_system_info()
        elif args.demo:
            if check_requirements():
                demo_mode()
        elif args.chat:
            if check_requirements():
                simple_chat_mode()
        else:
            # ì¸ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€í™”í˜• ë©”ë‰´ ì‹¤í–‰
            interactive_menu()

    except KeyboardInterrupt:
        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()