# vision_generator.py
# ì‹œê°-ì–¸ì–´ ëª¨ë¸ ê¸°ëŠ¥

import torch
import time
from PIL import Image
import requests
import base64
import io
from typing import Dict, Any, Optional, Union, List
from core.model_manager import ModelManager
from core.config import Config
import logging

logger = logging.getLogger(__name__)

class VisionGenerator:
    """ì‹œê°-ì–¸ì–´ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, model_manager: ModelManager, config: Config):
        self.model_manager = model_manager
        self.config = config
        self.supported_formats = ['JPEG', 'PNG', 'WebP', 'BMP']
    
    def _load_image(self, image_input: Union[str, Image.Image, bytes]) -> Optional[Image.Image]:
        """ë‹¤ì–‘í•œ í˜•íƒœì˜ ì´ë¯¸ì§€ ì…ë ¥ì„ PIL Imageë¡œ ë³€í™˜"""
        try:
            if isinstance(image_input, Image.Image):
                return image_input
            
            elif isinstance(image_input, str):
                if image_input.startswith(('http://', 'https://')):
                    # URLì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
                    response = requests.get(image_input, stream=True, timeout=10)
                    response.raise_for_status()
                    image = Image.open(io.BytesIO(response.content))
                elif image_input.startswith('data:image'):
                    # Base64 ë°ì´í„° URL
                    header, data = image_input.split(',', 1)
                    image_bytes = base64.b64decode(data)
                    image = Image.open(io.BytesIO(image_bytes))
                else:
                    # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
                    image = Image.open(image_input)
            
            elif isinstance(image_input, bytes):
                # ë°”ì´íŠ¸ ë°ì´í„°
                image = Image.open(io.BytesIO(image_input))
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ ì…ë ¥ í˜•íƒœ: {type(image_input)}")
            
            # ì´ë¯¸ì§€ í¬ë§· í™•ì¸
            if image.format not in self.supported_formats:
                print(f"âš ï¸ ê²½ê³ : {image.format} í¬ë§·ì€ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # RGBë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            return image
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _preprocess_image(self, image: Image.Image, max_size: int = 1024) -> Image.Image:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í¬ê¸° ì¡°ì • ë“±)"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ë° ì¡°ì •
            width, height = image.size
            
            if max(width, height) > max_size:
                # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
                if width > height:
                    new_width = max_size
                    new_height = int(height * max_size / width)
                else:
                    new_height = max_size
                    new_width = int(width * max_size / height)
                
                image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}")
            
            return image
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def generate_with_image(
        self,
        image_input: Union[str, Image.Image, bytes],
        prompt: str,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        preprocess: bool = True
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ì™€ í•¨ê»˜ í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            image_input: ì´ë¯¸ì§€ (URL, íŒŒì¼ê²½ë¡œ, PIL Image, ë°”ì´íŠ¸)
            prompt: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            temperature: ìƒì„± ì˜¨ë„
            preprocess: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ìƒì„± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        if not self.model_manager.is_loaded:
            return {
                "success": False,
                "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "response": None
            }
        
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ìƒì„± ì‹œì‘")
        print(f"ğŸ’¬ í”„ë¡¬í”„íŠ¸: {prompt}")
        
        start_time = time.time()
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self._load_image(image_input)
            if image is None:
                return {
                    "success": False,
                    "error": "ì´ë¯¸ì§€ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    "response": None
                }
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if preprocess:
                image = self._preprocess_image(image)
            
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            max_tokens = max_tokens or self.config.generation.max_tokens
            temperature = temperature or 0.1  # ì´ë¯¸ì§€ ë¶„ì„ì€ ë‚®ì€ ì˜¨ë„ ê¶Œì¥
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {'role': 'user', 'content': [
                    {'type': 'image'},
                    {'type': 'text', 'text': prompt}
                ]},
            ]
            
            # ì…ë ¥ í…ìŠ¤íŠ¸ ì²˜ë¦¬
            input_text = self.model_manager.processor.apply_chat_template(
                messages, 
                tokenize=False, 
                add_generation_prompt=True
            )
            
            # í† í¬ë‚˜ì´ì§• (ì´ë¯¸ì§€ í¬í•¨)
            inputs = self.model_manager.processor(
                image,
                input_text,
                add_special_tokens=False,
                return_tensors="pt",
            ).to(self.model_manager.device)
            
            print("ğŸ¤– ì´ë¯¸ì§€ ë¶„ì„ ë° ìƒì„± ì¤‘...")
            
            # ìƒì„±
            with torch.no_grad():
                output = self.model_manager.model.generate(
                    **inputs,
                    max_new_tokens=max_tokens,
                    temperature=temperature,
                    do_sample=temperature > 0,
                    eos_token_id=self.model_manager.processor.tokenizer.convert_tokens_to_ids('<|eot_id|>'),
                    use_cache=False,  # ë©”ëª¨ë¦¬ ì ˆì•½
                    pad_token_id=self.model_manager.processor.tokenizer.eos_token_id
                )
            
            # ë””ì½”ë”©
            full_response = self.model_manager.processor.decode(output[0], skip_special_tokens=True)
            
            # ì‘ë‹µ ì¶”ì¶œ
            clean_response = self._extract_response(full_response, input_text)
            
            generation_time = time.time() - start_time
            input_tokens = len(inputs['input_ids'][0])
            output_tokens = len(output[0]) - input_tokens
            tokens_per_second = output_tokens / generation_time if generation_time > 0 else 0
            
            print(f"âœ¨ ì‘ë‹µ: {clean_response}")
            print(f"â±ï¸ ìƒì„± ì‹œê°„: {generation_time:.2f}ì´ˆ")
            print(f"ğŸš€ ì†ë„: {tokens_per_second:.1f} í† í°/ì´ˆ")
            
            return {
                "success": True,
                "response": clean_response,
                "full_response": full_response,
                "generation_time": generation_time,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "tokens_per_second": tokens_per_second,
                "image_size": image.size,
                "parameters": {
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "preprocess": preprocess
                }
            }
            
        except torch.cuda.OutOfMemoryError:
            self.model_manager.clear_memory()
            error_msg = "VRAM ë¶€ì¡±! ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ë” ë§ì€ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "response": None
            }
            
        except Exception as e:
            error_msg = f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            print(f"âŒ {error_msg}")
            logger.error(f"Vision generation failed: {e}")
            return {
                "success": False,
                "error": error_msg,
                "response": None
            }
    
    def _extract_response(self, full_response: str, input_text: str) -> str:
        """ì‘ë‹µì—ì„œ ì‹¤ì œ ìƒì„±ëœ ë¶€ë¶„ë§Œ ì¶”ì¶œ"""
        try:
            if "assistant\n\n" in full_response:
                response_start = full_response.find("assistant\n\n") + len("assistant\n\n")
                clean_response = full_response[response_start:].strip()
            elif "assistant" in full_response:
                clean_response = full_response.split("assistant")[-1].strip()
            else:
                clean_response = full_response.replace(input_text, "").strip()
            
            # íŠ¹ìˆ˜ í† í° ì •ë¦¬
            clean_response = clean_response.replace('<|eot_id|>', '').strip()
            
            return clean_response
            
        except Exception as e:
            logger.warning(f"Response extraction failed: {e}")
            return full_response
    
    def describe_image(self, image_input: Union[str, Image.Image, bytes]) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
        return self.generate_with_image(
            image_input,
            "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”? ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            max_tokens=200,
            temperature=0.1
        )
    
    def extract_text(self, image_input: Union[str, Image.Image, bytes]) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)"""
        return self.generate_with_image(
            image_input,
            "ì´ ì´ë¯¸ì§€ì— ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì ì–´ì£¼ì„¸ìš”.",
            max_tokens=300,
            temperature=0.0
        )
    
    def analyze_chart(self, image_input: Union[str, Image.Image, bytes]) -> Dict[str, Any]:
        """ì°¨íŠ¸/ê·¸ë˜í”„ ë¶„ì„"""
        return self.generate_with_image(
            image_input,
            "ì´ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. ì£¼ìš” ë°ì´í„°, íŠ¸ë Œë“œ, íŒ¨í„´ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            max_tokens=300,
            temperature=0.1
        )
    
    def analyze_table(self, image_input: Union[str, Image.Image, bytes]) -> Dict[str, Any]:
        """í‘œ ë¶„ì„"""
        return self.generate_with_image(
            image_input,
            "ì´ í‘œì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”. ì¤‘ìš”í•œ ì •ë³´ì™€ íŒ¨í„´ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            max_tokens=400,
            temperature=0.1
        )
    
    def convert_to_markdown(self, image_input: Union[str, Image.Image, bytes]) -> Dict[str, Any]:
        """ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        return self.generate_with_image(
            image_input,
            "ì´ ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. êµ¬ì¡°ì™€ í˜•ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ì •í™•íˆ ë³€í™˜í•´ì£¼ì„¸ìš”.",
            max_tokens=500,
            temperature=0.0
        )
    
    def answer_visual_question(
        self, 
        image_input: Union[str, Image.Image, bytes], 
        question: str
    ) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ ë‹µë³€"""
        return self.generate_with_image(
            image_input,
            f"ì§ˆë¬¸: {question}\n\nì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ìœ„ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.",
            max_tokens=250,
            temperature=0.1
        )
    
    def batch_analyze_images(
        self, 
        image_inputs: List[Union[str, Image.Image, bytes]], 
        prompt: str,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ë¶„ì„"""
        results = []
        
        print(f"ğŸ“¦ ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {len(image_inputs)}ê°œ ì´ë¯¸ì§€")
        
        for i, image_input in enumerate(image_inputs):
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {i+1}/{len(image_inputs)}")
            
            try:
                result = self.generate_with_image(image_input, prompt, **kwargs)
                results.append(result)
            except Exception as e:
                print(f"âŒ ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                results.append({
                    "success": False,
                    "error": str(e),
                    "response": None,
                    "image_index": i
                })
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if i % 3 == 2:  # 3ê°œë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬
                self.model_manager.clear_memory()
        
        print("âœ… ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!")
        return results


class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self, vision_generator: VisionGenerator):
        self.vision_generator = vision_generator
    
    def process_document_page(
        self, 
        image_input: Union[str, Image.Image, bytes],
        task: str = "extract"
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ í˜ì´ì§€ ì²˜ë¦¬
        
        Args:
            image_input: ë¬¸ì„œ ì´ë¯¸ì§€
            task: ì²˜ë¦¬ ì‘ì—… ("extract", "summarize", "markdown", "table")
        """
        
        prompts = {
            "extract": "ì´ ë¬¸ì„œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.",
            "summarize": "ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” í¬ì¸íŠ¸ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.",
            "markdown": "ì´ ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. ì œëª©, ëª©ë¡, í‘œ ë“±ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.",
            "table": "ì´ ë¬¸ì„œì— ìˆëŠ” í‘œì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”."
        }
        
        prompt = prompts.get(task, prompts["extract"])
        max_tokens = 500 if task in ["markdown", "table"] else 300
        
        return self.vision_generator.generate_with_image(
            image_input,
            prompt,
            max_tokens=max_tokens,
            temperature=0.0
        )
    
    def process_multi_page_document(
        self, 
        image_inputs: List[Union[str, Image.Image, bytes]],
        task: str = "extract"
    ) -> Dict[str, Any]:
        """ë‹¤ì¤‘ í˜ì´ì§€ ë¬¸ì„œ ì²˜ë¦¬"""
        
        print(f"ğŸ“„ ë‹¤ì¤‘ í˜ì´ì§€ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {len(image_inputs)}í˜ì´ì§€")
        
        page_results = []
        combined_content = []
        
        for i, image_input in enumerate(image_inputs):
            print(f"ğŸ“ƒ í˜ì´ì§€ {i+1}/{len(image_inputs)} ì²˜ë¦¬ ì¤‘...")
            
            result = self.process_document_page(image_input, task)
            page_results.append(result)
            
            if result["success"]:
                combined_content.append(f"=== í˜ì´ì§€ {i+1} ===\n{result['response']}\n")
            else:
                combined_content.append(f"=== í˜ì´ì§€ {i+1} ===\nì˜¤ë¥˜: {result['error']}\n")
        
        # ì „ì²´ ë‚´ìš© ê²°í•©
        full_content = "\n".join(combined_content)
        
        return {
            "success": True,
            "page_results": page_results,
            "combined_content": full_content,
            "total_pages": len(image_inputs),
            "successful_pages": len([r for r in page_results if r["success"]])
        }


if __name__ == "__main__":
    # ì‹œê°-ì–¸ì–´ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
    from config import config
    from model_manager import get_model_manager
    
    # ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = get_model_manager(config)
    
    if manager.load_model():
        # ì‹œê°-ì–¸ì–´ ìƒì„±ê¸° ì´ˆê¸°í™”
        vision_gen = VisionGenerator(manager, config)
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ URL
        test_image = "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/React-icon.svg/1200px-React-icon.svg.png"
        
        # ì´ë¯¸ì§€ ì„¤ëª… í…ŒìŠ¤íŠ¸
        result = vision_gen.describe_image(test_image)
        print(f"ì´ë¯¸ì§€ ì„¤ëª…: {result}")
        
        # ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€ í…ŒìŠ¤íŠ¸
        qa_result = vision_gen.answer_visual_question(
            test_image, 
            "ì´ ë¡œê³ ëŠ” ì–´ë–¤ ê¸°ìˆ ì„ ë‚˜íƒ€ë‚´ë‚˜ìš”?"
        )
        print(f"ì§ˆë¬¸ ë‹µë³€: {qa_result}")
        
        # ë¬¸ì„œ ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸
        doc_processor = DocumentProcessor(vision_gen)
        
        manager.unload_model()
    else:
        print("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!")