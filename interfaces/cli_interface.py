# cli_interface.py
# ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤

import argparse
import sys
import os
from typing import Optional
import json
import time

from core.config import Config, setup_environment
from core.model_manager import get_model_manager
from core.text_generator import TextGenerator, ConversationManager
from core.vision_generator import VisionGenerator, DocumentProcessor

class CLIInterface:
    """ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = None
        self.model_manager = None
        self.text_generator = None
        self.vision_generator = None
        self.conversation_manager = None
        
    def setup(self, config_file: Optional[str] = None):
        """CLI ì„¤ì •"""
        print("ğŸŒ¸ Korean Bllossom AICA-5B CLI ì‹œì‘")
        print("=" * 50)
        
        # í™˜ê²½ ì„¤ì •
        setup_environment()
        
        # ì„¤ì • ë¡œë“œ
        self.config = Config(config_file)
        self.config.print_config()
        
        # ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.model_manager = get_model_manager(self.config)
        
        # ìƒì„±ê¸° ì´ˆê¸°í™”
        self.text_generator = TextGenerator(self.model_manager, self.config)
        self.vision_generator = VisionGenerator(self.model_manager, self.config)
        self.conversation_manager = ConversationManager(self.text_generator)
    
    def load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        print("\nğŸš€ ëª¨ë¸ ë¡œë”© ì¤‘...")
        success = self.model_manager.load_model()
        
        if success:
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            self.model_manager.optimize_for_inference()
            return True
        else:
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!")
            return False
    
    def text_mode(self, args):
        """í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë“œ"""
        if not self.model_manager.is_loaded:
            if not self.load_model():
                return
        
        if args.interactive:
            self._interactive_text_mode(args)
        else:
            self._single_text_generation(args)
    
    def _single_text_generation(self, args):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ìƒì„±"""
        prompt = args.prompt or input("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        
        result = self.text_generator.generate(
            prompt,
            max_tokens=args.max_tokens,
            temperature=args.temperature,
            top_p=args.top_p,
            top_k=args.top_k,
            system_message=args.system_message
        )
        
        if result["success"]:
            print(f"\nâœ¨ ìƒì„±ëœ í…ìŠ¤íŠ¸:\n{result['response']}")
            
            if args.verbose:
                print(f"\nğŸ“Š í†µê³„:")
                print(f"   ìƒì„± ì‹œê°„: {result['generation_time']:.2f}ì´ˆ")
                print(f"   ì…ë ¥ í† í°: {result['input_tokens']}")
                print(f"   ì¶œë ¥ í† í°: {result['output_tokens']}")
                print(f"   ì†ë„: {result['tokens_per_second']:.1f} í† í°/ì´ˆ")
            
            if args.output:
                self._save_result(result, args.output)
        else:
            print(f"âŒ ìƒì„± ì‹¤íŒ¨: {result['error']}")
    
    def _interactive_text_mode(self, args):
        """ëŒ€í™”í˜• í…ìŠ¤íŠ¸ ëª¨ë“œ"""
        print("\nğŸ’¬ ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘!")
        print("ëª…ë ¹ì–´:")
        print("  /help - ë„ì›€ë§")
        print("  /clear - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")
        print("  /save - ëŒ€í™” ì €ì¥")
        print("  /stats - ëª¨ë¸ ì •ë³´")
        print("  /quit - ì¢…ë£Œ")
        print("-" * 30)
        
        if args.system_message:
            self.conversation_manager.set_system_message(args.system_message)
            print(f"ğŸ¤– ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •: {args.system_message}")
        
        while True:
            try:
                user_input = input("\nì‚¬ìš©ì: ").strip()
                
                if not user_input:
                    continue
                
                # ëª…ë ¹ì–´ ì²˜ë¦¬
                if user_input.startswith('/'):
                    if user_input == '/quit':
                        print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break
                    elif user_input == '/help':
                        self._print_help()
                    elif user_input == '/clear':
                        self.conversation_manager.clear_history()
                    elif user_input == '/save':
                        filename = self.conversation_manager.export_conversation()
                        if filename:
                            print(f"ğŸ’¾ ëŒ€í™”ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
                    elif user_input == '/stats':
                        self._print_model_stats()
                    else:
                        print("â“ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. /helpë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")
                    continue
                
                # í…ìŠ¤íŠ¸ ìƒì„±
                result = self.conversation_manager.generate_response(
                    user_input,
                    max_tokens=args.max_tokens,
                    temperature=args.temperature,
                    top_p=args.top_p,
                    top_k=args.top_k
                )
                
                if result["success"]:
                    print(f"AI: {result['response']}")
                    
                    if args.verbose:
                        print(f"[â±ï¸ {result['generation_time']:.1f}s, ğŸš€ {result['tokens_per_second']:.1f} t/s]")
                else:
                    print(f"âŒ ì˜¤ë¥˜: {result['error']}")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                self.model_manager.clear_memory()
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def vision_mode(self, args):
        """ì‹œê°-ì–¸ì–´ ëª¨ë“œ"""
        if not self.model_manager.is_loaded:
            if not self.load_model():
                return
        
        if args.task == "describe":
            result = self.vision_generator.describe_image(args.image)
        elif args.task == "ocr":
            result = self.vision_generator.extract_text(args.image)
        elif args.task == "chart":
            result = self.vision_generator.analyze_chart(args.image)
        elif args.task == "table":
            result = self.vision_generator.analyze_table(args.image)
        elif args.task == "markdown":
            result = self.vision_generator.convert_to_markdown(args.image)
        elif args.task == "qa":
            if not args.prompt:
                prompt = input("ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            else:
                prompt = args.prompt
            result = self.vision_generator.answer_visual_question(args.image, prompt)
        else:
            # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸
            prompt = args.prompt or "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            result = self.vision_generator.generate_with_image(
                args.image,
                prompt,
                max_tokens=args.max_tokens,
                temperature=args.temperature
            )
        
        if result["success"]:
            print(f"\nâœ¨ ë¶„ì„ ê²°ê³¼:\n{result['response']}")
            
            if args.verbose:
                print(f"\nğŸ“Š í†µê³„:")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {result.get('image_size', 'Unknown')}")
                print(f"   ìƒì„± ì‹œê°„: {result['generation_time']:.2f}ì´ˆ")
                print(f"   ì†ë„: {result['tokens_per_second']:.1f} í† í°/ì´ˆ")
            
            if args.output:
                self._save_result(result, args.output)
        else:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
    
    def document_mode(self, args):
        """ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“œ"""
        if not self.model_manager.is_loaded:
            if not self.load_model():
                return
        
        doc_processor = DocumentProcessor(self.vision_generator)
        
        if args.multi_page:
            # ë‹¤ì¤‘ í˜ì´ì§€ ì²˜ë¦¬
            image_files = []
            if os.path.isdir(args.image):
                # ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
                for file in sorted(os.listdir(args.image)):
                    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.webp')):
                        image_files.append(os.path.join(args.image, file))
            else:
                # ë‹¨ì¼ íŒŒì¼
                image_files = [args.image]
            
            print(f"ğŸ“„ {len(image_files)}ê°œ í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
            result = doc_processor.process_multi_page_document(image_files, args.task)
            
            if args.output:
                self._save_document_result(result, args.output)
            else:
                print(f"\nğŸ“‹ ë¬¸ì„œ ì²˜ë¦¬ ê²°ê³¼:\n{result['combined_content']}")
        else:
            # ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬
            result = doc_processor.process_document_page(args.image, args.task)
            
            if result["success"]:
                print(f"\nğŸ“‹ ë¬¸ì„œ ì²˜ë¦¬ ê²°ê³¼:\n{result['response']}")
                
                if args.output:
                    self._save_result(result, args.output)
            else:
                print(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
    
    def batch_mode(self, args):
        """ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ"""
        if not self.model_manager.is_loaded:
            if not self.load_model():
                return
        
        try:
            with open(args.input_file, 'r', encoding='utf-8') as f:
                if args.input_file.endswith('.json'):
                    batch_data = json.load(f)
                else:
                    # í…ìŠ¤íŠ¸ íŒŒì¼ (í•œ ì¤„ì— í•˜ë‚˜ì”©)
                    prompts = [line.strip() for line in f if line.strip()]
                    batch_data = [{"prompt": p} for p in prompts]
            
            print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(batch_data)}ê°œ í•­ëª©")
            
            results = []
            for i, item in enumerate(batch_data):
                print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {i+1}/{len(batch_data)}")
                
                if "image" in item:
                    # ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
                    result = self.vision_generator.generate_with_image(
                        item["image"],
                        item["prompt"],
                        max_tokens=args.max_tokens,
                        temperature=args.temperature
                    )
                else:
                    # í…ìŠ¤íŠ¸ë§Œ
                    result = self.text_generator.generate(
                        item["prompt"],
                        max_tokens=args.max_tokens,
                        temperature=args.temperature
                    )
                
                results.append({
                    "input": item,
                    "output": result,
                    "index": i
                })
                
                # ì§„í–‰ë¥  ì¶œë ¥
                if (i + 1) % 10 == 0:
                    print(f"ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(batch_data)} ({((i+1)/len(batch_data)*100):.1f}%)")
            
            # ê²°ê³¼ ì €ì¥
            output_file = args.output or f"batch_results_{int(time.time())}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_file}")
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _save_result(self, result: dict, filename: str):
        """ê²°ê³¼ ì €ì¥"""
        try:
            if filename.endswith('.json'):
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
            else:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(result['response'])
            
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {filename}")
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_document_result(self, result: dict, filename: str):
        """ë¬¸ì„œ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥"""
        try:
            if filename.endswith('.json'):
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
            else:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(result['combined_content'])
            
            print(f"ğŸ’¾ ë¬¸ì„œ ê²°ê³¼ ì €ì¥: {filename}")
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _print_help(self):
        """ë„ì›€ë§ ì¶œë ¥"""
        print("\nğŸ“– ë„ì›€ë§:")
        print("  /help - ì´ ë„ì›€ë§ í‘œì‹œ")
        print("  /clear - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")
        print("  /save - í˜„ì¬ ëŒ€í™”ë¥¼ íŒŒì¼ë¡œ ì €ì¥")
        print("  /stats - ëª¨ë¸ ë° ë©”ëª¨ë¦¬ ì •ë³´ í‘œì‹œ")
        print("  /quit - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    
    def _print_model_stats(self):
        """ëª¨ë¸ í†µê³„ ì¶œë ¥"""
        info = self.model_manager.get_model_info()
        print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
        for key, value in info.items():
            print(f"   {key}: {value}")
        
        self.model_manager._print_memory_usage()


def create_parser():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì„œ ìƒì„±"""
    parser = argparse.ArgumentParser(
        description="Korean Bllossom AICA-5B CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì œ:
  # í…ìŠ¤íŠ¸ ìƒì„±
  python cli_interface.py text "ì•ˆë…•í•˜ì„¸ìš”" --max-tokens 100
  
  # ëŒ€í™”í˜• ëª¨ë“œ
  python cli_interface.py text --interactive
  
  # ì´ë¯¸ì§€ ì„¤ëª…
  python cli_interface.py vision image.jpg --task describe
  
  # OCR (í…ìŠ¤íŠ¸ ì¶”ì¶œ)
  python cli_interface.py vision document.png --task ocr
  
  # ë¬¸ì„œ ì²˜ë¦¬
  python cli_interface.py document doc.png --task markdown
  
  # ë°°ì¹˜ ì²˜ë¦¬
  python cli_interface.py batch prompts.txt --output results.json
        """
    )
    
    # ì „ì—­ ì˜µì…˜
    parser.add_argument('--config', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ì •ë³´ ì¶œë ¥')
    parser.add_argument('--output', '-o', type=str, help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    
    # ì„œë¸Œ ì»¤ë§¨ë“œ
    subparsers = parser.add_subparsers(dest='mode', help='ì‹¤í–‰ ëª¨ë“œ')
    
    # í…ìŠ¤íŠ¸ ëª¨ë“œ
    text_parser = subparsers.add_parser('text', help='í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë“œ')
    text_parser.add_argument('prompt', nargs='?', help='ì…ë ¥ í”„ë¡¬í”„íŠ¸')
    text_parser.add_argument('--interactive', '-i', action='store_true', help='ëŒ€í™”í˜• ëª¨ë“œ')
    text_parser.add_argument('--max-tokens', type=int, default=256, help='ìµœëŒ€ í† í° ìˆ˜')
    text_parser.add_argument('--temperature', type=float, default=0.7, help='ìƒì„± ì˜¨ë„')
    text_parser.add_argument('--top-p', type=float, default=0.9, help='Top-p íŒŒë¼ë¯¸í„°')
    text_parser.add_argument('--top-k', type=int, default=50, help='Top-k íŒŒë¼ë¯¸í„°')
    text_parser.add_argument('--system-message', type=str, help='ì‹œìŠ¤í…œ ë©”ì‹œì§€')
    
    # ì‹œê° ëª¨ë“œ
    vision_parser = subparsers.add_parser('vision', help='ì‹œê°-ì–¸ì–´ ëª¨ë“œ')
    vision_parser.add_argument('image', help='ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URL')
    vision_parser.add_argument('--task', choices=['describe', 'ocr', 'chart', 'table', 'markdown', 'qa', 'custom'], 
                               default='describe', help='ë¶„ì„ ì‘ì—…')
    vision_parser.add_argument('--prompt', type=str, help='ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸')
    vision_parser.add_argument('--max-tokens', type=int, default=300, help='ìµœëŒ€ í† í° ìˆ˜')
    vision_parser.add_argument('--temperature', type=float, default=0.1, help='ìƒì„± ì˜¨ë„')
    
    # ë¬¸ì„œ ëª¨ë“œ
    doc_parser = subparsers.add_parser('document', help='ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“œ')
    doc_parser.add_argument('image', help='ë¬¸ì„œ ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬')
    doc_parser.add_argument('--task', choices=['extract', 'summarize', 'markdown', 'table'], 
                            default='extract', help='ë¬¸ì„œ ì²˜ë¦¬ ì‘ì—…')
    doc_parser.add_argument('--multi-page', action='store_true', help='ë‹¤ì¤‘ í˜ì´ì§€ ë¬¸ì„œ')
    
    # ë°°ì¹˜ ëª¨ë“œ
    batch_parser = subparsers.add_parser('batch', help='ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ')
    batch_parser.add_argument('input_file', help='ì…ë ¥ íŒŒì¼ (JSON ë˜ëŠ” í…ìŠ¤íŠ¸)')
    batch_parser.add_argument('--max-tokens', type=int, default=256, help='ìµœëŒ€ í† í° ìˆ˜')
    batch_parser.add_argument('--temperature', type=float, default=0.7, help='ìƒì„± ì˜¨ë„')
    
    return parser


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = create_parser()
    args = parser.parse_args()
    
    if not args.mode:
        parser.print_help()
        return
    
    # CLI ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
    cli = CLIInterface()
    cli.setup(args.config)
    
    try:
        # ëª¨ë“œë³„ ì‹¤í–‰
        if args.mode == 'text':
            cli.text_mode(args)
        elif args.mode == 'vision':
            cli.vision_mode(args)
        elif args.mode == 'document':
            cli.document_mode(args)
        elif args.mode == 'batch':
            cli.batch_mode(args)
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
    finally:
        # ì •ë¦¬
        if cli.model_manager and cli.model_manager.is_loaded:
            cli.model_manager.unload_model()


if __name__ == "__main__":
    main()
